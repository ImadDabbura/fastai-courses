{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from exp.nb_01 import *\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid),\n",
    "         _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train, y_train, x_valid, y_valid))\n",
    "\n",
    "\n",
    "def normalize(x, m, s):\n",
    "    return (x - m) / s\n",
    "\n",
    "\n",
    "def test_near_zero(a, tol=1e-3):\n",
    "    assert a.abs() < tol, f\"Near zero: {a}\"\n",
    "\n",
    "\n",
    "def mse(output, targ):\n",
    "    return (output.squeeze(-1) - targ).pow(2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return x.exp() / x.exp().sum(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    a = x.max(-1)[0]\n",
    "    return x - (a + (x - a[..., None]).exp().sum(-1).log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def nll(inp, target):\n",
    "    return - inp[range(len(inp)), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [4, 3]])\n",
    "a.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def accuracy(out, target):\n",
    "    return (out.argmax(dim=1) == target).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class DummyModel:\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "\n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith('_'):\n",
    "            self._modules[k] = v\n",
    "        super().__setattr__(k, v)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self._modules}'\n",
    "\n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            for p in l.parameters():\n",
    "                yield p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=10, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=1, bias=True)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DummyModel(10, 50, 1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 2.0481e-01, -3.5641e-02, -2.8826e-01, -2.4427e-01, -2.5293e-01,\n",
       "           5.5174e-02,  1.5537e-01,  7.5775e-02, -1.0442e-02, -8.7140e-02],\n",
       "         [ 8.3952e-02, -3.0404e-01, -5.0348e-02, -1.8344e-01, -1.7903e-01,\n",
       "          -6.9925e-02,  2.3370e-01,  1.8883e-01,  7.2590e-02,  1.4053e-01],\n",
       "         [ 1.4514e-01,  1.3608e-01,  2.3757e-01,  2.5917e-01,  6.9273e-02,\n",
       "          -4.6451e-02, -6.7264e-04, -1.1190e-01, -9.1599e-02,  1.3182e-01],\n",
       "         [ 5.4460e-02, -1.3481e-02,  2.1853e-01, -1.4235e-01, -1.2561e-01,\n",
       "          -2.4741e-01,  1.2656e-01,  1.4360e-01, -1.7623e-01, -2.6897e-03],\n",
       "         [ 1.6779e-01, -1.0617e-01,  1.8345e-01,  1.6497e-01,  1.1530e-01,\n",
       "           2.6983e-01, -3.1355e-01,  3.0751e-01, -2.0166e-01, -1.4336e-01],\n",
       "         [-1.1560e-01,  5.0659e-03, -2.1951e-01, -1.5410e-02,  2.6934e-01,\n",
       "           3.1324e-01,  1.4645e-02, -1.9744e-01,  1.9808e-01, -3.0895e-01],\n",
       "         [ 2.7753e-01, -2.3856e-01,  7.3735e-02,  7.0507e-02, -2.7652e-01,\n",
       "          -1.7749e-01, -2.3127e-01, -2.8565e-01, -1.2041e-01, -2.1800e-01],\n",
       "         [ 2.4377e-01,  2.2425e-01,  1.3135e-01, -1.5454e-01,  3.2260e-02,\n",
       "           7.6343e-02,  1.6929e-01, -2.3091e-01, -9.5124e-02, -2.1952e-01],\n",
       "         [-2.8435e-01, -2.9714e-01, -2.9885e-01, -1.0160e-01, -9.5168e-04,\n",
       "          -1.3207e-01, -1.6843e-01, -1.2432e-01, -2.6838e-01, -1.4581e-02],\n",
       "         [-2.2227e-01,  3.1514e-01, -7.6032e-02,  1.9457e-01, -2.0513e-01,\n",
       "          -1.3226e-01,  1.7386e-01, -6.9542e-02, -1.4215e-01, -2.3075e-02],\n",
       "         [ 2.7964e-01, -2.7851e-01,  2.9076e-01,  1.1754e-01, -4.9807e-02,\n",
       "          -4.5130e-02,  1.2672e-01,  7.3977e-02, -2.5350e-01, -6.8633e-02],\n",
       "         [ 2.1632e-01, -1.6169e-01, -2.2477e-01,  5.1132e-02,  1.2802e-02,\n",
       "          -2.1818e-01, -1.2557e-01, -2.4341e-02,  2.4680e-01, -1.3343e-01],\n",
       "         [ 2.0028e-01, -1.0338e-01, -1.8557e-01, -4.2997e-02,  2.0252e-01,\n",
       "          -8.8689e-02,  1.8118e-01,  3.8922e-02,  2.1931e-01,  5.8374e-03],\n",
       "         [ 6.8139e-02,  1.7402e-01, -1.8454e-01, -2.6582e-01, -1.8079e-01,\n",
       "          -7.8399e-02, -5.9663e-02,  2.2310e-01, -5.0769e-02, -9.2085e-02],\n",
       "         [ 2.9869e-02, -1.1806e-01, -9.0299e-03, -2.7803e-02,  9.5361e-02,\n",
       "           4.5597e-03, -1.8277e-01,  1.1517e-01,  2.1766e-01,  2.8503e-01],\n",
       "         [-5.8419e-02, -1.2633e-01,  2.8161e-01,  1.4487e-01, -1.5433e-01,\n",
       "           1.5359e-02, -1.3318e-01, -2.2750e-01,  1.1475e-01,  1.6075e-01],\n",
       "         [ 2.9463e-01,  2.1590e-01, -2.5874e-01, -1.1016e-01,  5.3060e-02,\n",
       "          -1.1732e-02, -1.0424e-01,  7.7309e-02,  3.1230e-01,  1.4469e-01],\n",
       "         [-2.7771e-01,  3.7748e-02,  2.1748e-01, -1.0772e-02,  2.3206e-02,\n",
       "          -9.9365e-02,  2.5550e-01,  3.0294e-01,  1.5842e-01,  4.4103e-02],\n",
       "         [ 1.4053e-02, -1.9113e-01,  1.7945e-01,  1.7087e-01, -2.4399e-01,\n",
       "           9.5010e-05,  2.3692e-01, -3.6469e-02,  1.7399e-02,  2.0097e-01],\n",
       "         [-6.5450e-03, -2.2487e-01,  1.9149e-01, -1.5091e-01,  2.4371e-01,\n",
       "          -6.9737e-02, -1.5727e-01, -1.1337e-01,  1.9434e-01,  1.7731e-02],\n",
       "         [ 7.8990e-02, -1.3489e-02,  2.4073e-01,  5.5341e-02, -1.6037e-01,\n",
       "          -1.2907e-01, -2.8330e-01, -2.3587e-01,  1.9336e-01, -1.5358e-01],\n",
       "         [ 4.6935e-02, -1.4644e-01,  1.5696e-01, -7.7109e-02, -2.9877e-02,\n",
       "           2.5618e-01,  2.0650e-01,  2.0103e-01,  8.1571e-02, -2.4560e-01],\n",
       "         [ 3.0714e-01, -2.6860e-01,  2.5160e-01,  1.5764e-01,  1.4696e-01,\n",
       "           2.5080e-01,  1.3418e-01,  2.2946e-01, -2.2347e-01,  1.8515e-01],\n",
       "         [-1.5306e-01,  6.0927e-02,  1.6678e-01,  5.6407e-02,  2.8397e-01,\n",
       "           1.0714e-01,  2.3447e-02, -2.5809e-01,  1.1427e-01, -2.8774e-01],\n",
       "         [-2.4021e-01, -2.5818e-01,  2.3425e-01,  2.3351e-01,  2.1582e-01,\n",
       "          -1.5594e-02,  1.9865e-01,  1.4200e-02,  2.4352e-01,  1.0418e-01],\n",
       "         [-1.6866e-02,  3.0790e-01,  1.5308e-01,  5.5868e-02,  2.2591e-01,\n",
       "          -1.3920e-01,  1.0626e-01, -9.5659e-04,  2.5690e-01, -1.1454e-01],\n",
       "         [ 1.3812e-01, -2.4837e-01, -1.4918e-01,  7.9907e-02, -1.2930e-01,\n",
       "          -2.9781e-01, -2.1938e-02,  1.8948e-01,  1.9615e-01, -2.5266e-01],\n",
       "         [-2.4559e-01, -1.1318e-01,  7.2723e-02,  1.4689e-01,  1.9731e-01,\n",
       "           2.1300e-01,  3.0639e-01, -1.3131e-01,  1.9703e-01,  2.6762e-01],\n",
       "         [ 2.3055e-01,  7.8206e-02, -3.5673e-03,  2.3671e-01, -2.6783e-01,\n",
       "           1.2001e-01,  1.6763e-01,  1.6232e-01, -8.4062e-02,  1.6034e-01],\n",
       "         [ 1.8379e-01, -4.5661e-02,  1.2814e-01,  3.1202e-01, -1.5599e-01,\n",
       "          -1.3600e-01, -1.3832e-01,  1.3284e-01, -2.9752e-01,  1.2409e-01],\n",
       "         [-1.9062e-01,  2.0603e-01,  1.1488e-01, -7.4440e-02, -2.0605e-04,\n",
       "          -4.5977e-02, -7.8313e-02,  3.0566e-01,  1.5765e-01,  2.4482e-01],\n",
       "         [-2.4990e-01, -2.0008e-01, -2.7130e-02,  7.2996e-03, -1.3760e-01,\n",
       "           2.5401e-02,  5.6139e-02,  1.0533e-01,  4.5379e-02, -2.5010e-01],\n",
       "         [ 2.2574e-01, -2.7334e-01, -2.6211e-01, -6.0831e-02,  1.2072e-01,\n",
       "          -9.7697e-02,  1.8814e-02, -1.4549e-01,  2.9839e-01, -2.2608e-01],\n",
       "         [ 2.3749e-01, -6.4977e-02, -1.8792e-01,  2.2920e-01,  7.1289e-02,\n",
       "          -9.3061e-02,  2.6682e-01, -2.2226e-01, -2.9841e-01,  5.8928e-02],\n",
       "         [ 1.1511e-01, -1.0226e-01, -2.3316e-01, -2.2995e-01,  1.1975e-01,\n",
       "           2.4166e-01,  3.5978e-02,  1.3927e-01,  6.2488e-03, -9.8841e-03],\n",
       "         [ 4.7698e-02,  1.5555e-01,  3.0127e-01,  1.0761e-01, -1.8740e-01,\n",
       "           1.6682e-01, -2.4111e-01,  2.7934e-01, -4.0324e-02, -7.2732e-02],\n",
       "         [-1.0359e-02,  1.5083e-01,  1.8054e-01, -3.7421e-02, -1.9542e-01,\n",
       "           2.1843e-02,  9.0464e-02, -2.9321e-03,  3.0392e-01,  1.9138e-02],\n",
       "         [-1.5084e-01,  2.8780e-01, -9.3675e-04, -1.0111e-01,  1.7267e-02,\n",
       "          -6.7097e-02, -4.3041e-02, -2.5329e-01,  2.5119e-01,  1.0412e-01],\n",
       "         [ 1.8261e-01,  2.6942e-01,  1.6195e-01, -1.7968e-01,  1.3429e-01,\n",
       "          -1.4874e-01, -5.6653e-02, -2.8346e-02,  2.8534e-01,  2.3479e-01],\n",
       "         [ 2.8265e-01,  2.4056e-03,  2.2260e-01, -2.7981e-01,  2.1035e-01,\n",
       "          -9.3810e-02,  5.7045e-03, -1.0909e-02, -1.8918e-01,  2.5079e-01],\n",
       "         [-2.9376e-01, -2.9117e-01,  2.3613e-01, -4.4683e-02,  1.0655e-01,\n",
       "          -1.7752e-01, -4.5749e-02,  3.8391e-02,  2.7619e-01, -2.3624e-01],\n",
       "         [ 5.8648e-02,  3.7637e-02,  2.5338e-02, -2.5709e-01, -5.5935e-02,\n",
       "          -2.3025e-01,  2.0744e-01, -1.9527e-01,  1.6873e-01, -1.4179e-01],\n",
       "         [-7.8646e-02, -4.9129e-02,  4.6025e-02, -1.1900e-01, -9.3436e-02,\n",
       "          -3.0637e-01, -2.7751e-01, -9.4611e-02, -2.0069e-01,  1.1189e-01],\n",
       "         [-6.4197e-02,  7.3296e-02, -2.7884e-02, -1.7426e-01,  3.1347e-01,\n",
       "          -4.9843e-02,  2.8927e-02,  1.4970e-01,  1.8809e-01,  3.0145e-01],\n",
       "         [ 6.5872e-02,  1.9876e-01, -2.5982e-01, -1.7155e-01,  3.0445e-01,\n",
       "          -1.9317e-01, -1.7829e-01, -2.1766e-01, -2.2729e-01, -4.0306e-02],\n",
       "         [ 1.1285e-01, -2.5959e-01,  2.9174e-01, -2.8787e-01,  2.6271e-01,\n",
       "           8.6115e-02, -2.0892e-01,  1.5765e-01,  3.7897e-02,  3.0495e-01],\n",
       "         [ 2.4271e-01,  1.1365e-01,  4.6411e-02,  2.7731e-01, -2.6365e-01,\n",
       "           1.9075e-01,  1.8844e-01,  1.1125e-01,  3.2953e-02,  1.2080e-01],\n",
       "         [ 1.6568e-01, -2.3082e-01, -2.4924e-01,  1.3054e-01,  1.6448e-01,\n",
       "          -1.9749e-01, -1.5434e-01, -2.3802e-01,  1.6714e-01,  3.2672e-02],\n",
       "         [-9.3172e-02,  2.8933e-01, -1.7068e-01,  5.5656e-02,  4.5403e-02,\n",
       "          -8.9015e-02, -1.1715e-01,  2.8284e-01, -3.5155e-02,  4.8189e-02],\n",
       "         [ 1.7117e-01, -9.8902e-02,  7.6892e-02,  4.5511e-02,  6.4820e-03,\n",
       "           1.1646e-01, -1.7918e-01,  8.7964e-03,  3.0430e-01,  7.7653e-02]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2250,  0.1207, -0.2369,  0.0720,  0.0229, -0.1815,  0.2510, -0.0944,\n",
       "          0.2449,  0.0985,  0.2849,  0.0821, -0.1480,  0.0826,  0.0646, -0.0743,\n",
       "          0.0075,  0.0454, -0.2048, -0.0067,  0.1120, -0.0299,  0.0536,  0.2046,\n",
       "         -0.0005, -0.2732, -0.0902, -0.2312, -0.0082, -0.0283, -0.2347,  0.0486,\n",
       "          0.0993,  0.2267, -0.2614,  0.0905,  0.0848, -0.2716, -0.0472, -0.1050,\n",
       "         -0.0004,  0.0350,  0.2365,  0.2358, -0.1913, -0.1736,  0.2185,  0.0531,\n",
       "          0.0166,  0.0892], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0951, -0.0694, -0.0149, -0.1022,  0.1044,  0.0359, -0.0042, -0.1322,\n",
       "          -0.1268, -0.0439,  0.1186, -0.1363, -0.0769,  0.0112, -0.1008, -0.0257,\n",
       "          -0.1114, -0.1229,  0.1309, -0.0582, -0.0955,  0.0579, -0.1262,  0.1182,\n",
       "           0.0433, -0.1175, -0.0487,  0.1371,  0.0644,  0.1058,  0.0766, -0.0916,\n",
       "          -0.0315,  0.0709,  0.1262, -0.0624, -0.0269,  0.0680,  0.0874, -0.0220,\n",
       "          -0.1340,  0.0486, -0.0254, -0.0066, -0.1245, -0.1079,  0.1053,  0.0694,\n",
       "          -0.0635,  0.0203]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1209], requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([50, 10]), torch.Size([50]), torch.Size([1, 50]), torch.Size([1])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.l2(F.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (l1): Linear(in_features=10, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(10, 50, 1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('l1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 2.4020e-01,  8.9872e-02,  2.2179e-01, -4.9403e-02,  6.0188e-02,\n",
       "           -8.2237e-02, -2.5875e-01,  5.8769e-02, -2.9027e-01, -1.1395e-01],\n",
       "          [-1.0626e-01, -2.9756e-01,  8.2289e-02, -1.1705e-01, -8.8802e-02,\n",
       "            3.7548e-03,  6.5087e-03, -3.0153e-01, -6.0792e-02, -2.6864e-01],\n",
       "          [-9.5636e-02,  1.2715e-01, -2.9852e-01, -2.4876e-01, -2.4315e-01,\n",
       "           -2.4582e-01, -2.1988e-01, -3.2580e-02,  2.0303e-01,  1.9304e-02],\n",
       "          [ 2.5258e-01, -2.8663e-02,  1.7346e-01, -2.8764e-01, -9.1553e-02,\n",
       "            5.6161e-02, -2.5793e-02, -3.1943e-02,  8.6642e-02, -2.5092e-01],\n",
       "          [-1.8698e-01, -1.2135e-01,  9.9211e-02,  1.1476e-01,  2.8158e-01,\n",
       "           -1.7823e-01, -7.1022e-02,  2.6572e-01,  2.4877e-01,  2.1743e-01],\n",
       "          [-1.5481e-01,  2.2618e-02,  9.4337e-02,  1.5219e-01,  1.6154e-01,\n",
       "            9.7116e-02,  1.5017e-01,  2.6325e-01,  3.8464e-02,  2.9264e-01],\n",
       "          [-1.6648e-01, -3.0528e-01,  2.1135e-02,  2.4502e-01,  9.8601e-02,\n",
       "            6.4265e-02,  1.9532e-01,  2.8353e-01,  2.3808e-01,  2.5243e-01],\n",
       "          [-1.2639e-01,  1.3626e-01,  1.3651e-02,  2.3478e-01, -3.0871e-01,\n",
       "            3.6936e-02,  2.0872e-01, -9.0170e-02, -1.2402e-01, -1.5159e-01],\n",
       "          [-1.1454e-01, -1.4381e-01, -2.4274e-01, -3.0378e-01, -1.7290e-01,\n",
       "            4.2229e-02,  4.5771e-02,  2.4634e-01,  9.1000e-02, -3.0110e-01],\n",
       "          [ 1.8171e-01, -1.3900e-01, -8.7233e-02,  1.3225e-01,  2.9000e-01,\n",
       "           -2.4990e-01,  6.6392e-02, -2.7445e-01, -3.5408e-02, -2.9074e-01],\n",
       "          [ 2.8771e-01,  5.3667e-02,  1.3813e-02,  2.4886e-01, -1.9606e-01,\n",
       "           -8.9455e-02, -6.6589e-02, -9.1252e-02,  4.4143e-02,  1.0823e-01],\n",
       "          [-2.7226e-02,  2.7711e-01,  2.7384e-01,  1.1556e-01, -1.2063e-01,\n",
       "            1.2622e-01, -2.2182e-01,  3.5064e-02, -5.3610e-02,  1.2090e-01],\n",
       "          [-1.2296e-01,  1.5860e-01,  1.9288e-01,  5.9283e-02, -6.9947e-02,\n",
       "           -1.7532e-01,  8.3439e-02, -1.2195e-01,  7.2416e-02, -9.4714e-02],\n",
       "          [-1.0015e-01,  2.1949e-01, -2.9703e-01,  1.3414e-01,  1.3594e-01,\n",
       "            7.8940e-02,  2.5603e-01,  2.8754e-01,  9.2787e-02, -4.7535e-02],\n",
       "          [-2.9962e-01,  1.1997e-01, -1.1584e-01, -1.0675e-01,  1.3800e-01,\n",
       "            1.9411e-02,  1.2519e-01, -2.6985e-01, -2.4397e-01,  1.0134e-01],\n",
       "          [-2.2187e-01,  1.4441e-01,  8.5008e-02,  2.7600e-01, -2.2767e-01,\n",
       "           -2.6310e-01,  1.3448e-01,  1.0888e-01, -1.6542e-01,  3.0757e-01],\n",
       "          [-2.4280e-01, -1.1661e-01,  6.3554e-02, -8.9610e-04, -2.4797e-01,\n",
       "           -7.8017e-02, -1.4017e-01,  4.6478e-02, -2.8099e-01, -9.7551e-02],\n",
       "          [-6.5719e-02, -2.5484e-01,  1.1608e-01,  2.2711e-01,  1.3462e-01,\n",
       "            7.0326e-02,  2.2644e-01,  1.2941e-01, -4.7982e-02,  1.4549e-02],\n",
       "          [ 4.8018e-04, -2.4922e-01, -4.6428e-02,  1.9487e-01, -1.9685e-01,\n",
       "            4.7129e-02, -1.4740e-01,  2.7751e-01, -4.8576e-03,  7.6759e-02],\n",
       "          [-1.3167e-02,  1.4326e-01, -2.3957e-01, -2.6758e-01, -2.7020e-01,\n",
       "            2.2141e-01,  1.4127e-01, -3.1123e-01, -2.0487e-01, -2.4675e-01],\n",
       "          [-6.0238e-02,  5.3394e-02,  8.5177e-02,  2.5677e-01,  1.7996e-01,\n",
       "           -2.9532e-01,  1.7735e-01, -7.6031e-02,  1.9825e-02, -1.4057e-01],\n",
       "          [-1.3108e-01,  2.8086e-01,  3.8237e-02,  1.6388e-01, -1.6995e-01,\n",
       "           -6.8338e-02,  1.5235e-01, -8.7155e-02,  1.4432e-01, -1.2310e-01],\n",
       "          [-1.8651e-02,  1.4679e-01,  2.0026e-01,  8.3830e-02, -3.0609e-01,\n",
       "           -1.4896e-02, -2.4786e-02, -1.2361e-01,  1.2838e-01,  1.5535e-01],\n",
       "          [-2.0141e-01, -3.0375e-01,  3.0177e-01,  2.8893e-01,  2.7024e-01,\n",
       "           -7.7733e-02, -1.1076e-01, -1.1725e-02, -6.0036e-02, -5.1551e-02],\n",
       "          [-5.9673e-02, -2.1668e-02,  5.8624e-02,  1.4072e-01, -2.6149e-01,\n",
       "            1.6587e-01, -1.2699e-01, -2.4622e-01, -2.3290e-01,  1.3622e-01],\n",
       "          [ 6.8147e-02,  1.0033e-02,  1.9142e-02, -2.8521e-01,  3.7810e-02,\n",
       "            1.2606e-02,  8.7439e-02, -2.0421e-01, -4.7942e-02, -1.6424e-02],\n",
       "          [ 6.2269e-02, -2.1619e-01, -5.0694e-02, -1.2607e-02,  6.9707e-02,\n",
       "            1.5807e-01,  2.7590e-01,  2.9344e-02,  2.3251e-01,  8.0035e-02],\n",
       "          [-2.6354e-01,  5.8233e-02, -1.0253e-01, -2.2054e-01, -2.3963e-01,\n",
       "           -1.1640e-01, -1.3946e-01, -2.6625e-01, -1.4908e-01, -1.0247e-01],\n",
       "          [ 1.6275e-01, -3.8269e-02,  2.0424e-01, -2.0112e-01, -1.1886e-01,\n",
       "            2.7844e-01, -2.3419e-01, -1.9434e-01,  3.2791e-02,  1.1917e-02],\n",
       "          [ 1.1281e-01,  1.0289e-01, -8.8886e-02, -2.4871e-01,  3.0152e-01,\n",
       "           -4.1871e-02,  1.5448e-01,  1.8574e-01,  2.5145e-01,  3.7247e-02],\n",
       "          [ 3.1475e-01,  8.0373e-02,  1.5197e-01,  2.2422e-01,  1.5239e-01,\n",
       "           -6.3049e-02, -3.8789e-02, -2.7397e-01, -1.5811e-01,  9.1847e-02],\n",
       "          [-1.4972e-02,  1.7282e-02,  2.1391e-01,  2.7092e-01,  2.4513e-01,\n",
       "            1.8395e-01, -3.0868e-01, -1.2051e-01, -2.6598e-01,  2.4960e-01],\n",
       "          [-3.5623e-02,  6.7442e-02, -2.9999e-02, -2.6112e-01,  3.6647e-02,\n",
       "           -5.5604e-02,  3.0435e-02,  1.5645e-01,  2.1819e-01,  1.9677e-01],\n",
       "          [ 5.2856e-02,  1.8338e-02,  2.5764e-01,  8.6679e-02,  8.2023e-02,\n",
       "           -3.0117e-01, -1.3702e-02,  2.4487e-01, -2.6459e-01, -2.5971e-01],\n",
       "          [ 1.3579e-01, -2.7111e-01, -2.4369e-01, -2.5428e-01,  7.9960e-02,\n",
       "            2.7381e-01, -9.0948e-02, -3.8905e-02,  1.9116e-01, -3.3568e-02],\n",
       "          [-2.8313e-01, -2.9655e-02,  1.7628e-01, -2.9373e-02, -2.9256e-01,\n",
       "            1.1132e-01, -1.0448e-01,  2.0993e-01, -2.3173e-01,  2.4823e-01],\n",
       "          [ 2.3970e-01, -2.4703e-01, -6.6817e-02,  1.8484e-01,  1.6946e-01,\n",
       "            1.0712e-01,  1.5216e-02,  6.8985e-03,  1.7269e-01, -7.0630e-02],\n",
       "          [ 1.9662e-01,  2.1871e-02, -2.8963e-01, -1.0338e-01, -2.5630e-04,\n",
       "            3.1756e-02, -2.6470e-01,  2.7975e-01,  2.9932e-02, -2.5182e-02],\n",
       "          [-2.0394e-01, -2.1089e-01,  1.9453e-01,  7.5921e-02, -2.9731e-01,\n",
       "           -3.1629e-02, -3.1016e-01, -1.1217e-01, -2.2403e-01, -2.5203e-01],\n",
       "          [ 2.9372e-02,  1.4562e-01, -8.3820e-02, -6.2881e-03,  1.2109e-01,\n",
       "            1.2091e-01, -1.0628e-01, -7.2758e-02,  1.8334e-02,  4.7416e-02],\n",
       "          [ 1.7961e-01, -1.3053e-01,  8.8010e-02, -3.9008e-02,  2.1678e-01,\n",
       "            8.3155e-02, -1.4848e-01, -5.3362e-02, -2.3256e-01, -3.8381e-02],\n",
       "          [-2.9747e-01, -1.1684e-01, -2.0569e-01, -1.2057e-01, -1.7237e-01,\n",
       "            2.4908e-02, -2.9426e-01, -8.6472e-02,  1.1812e-02, -2.0138e-01],\n",
       "          [-4.9658e-03, -1.7517e-01, -1.5282e-01,  2.9727e-01, -1.3144e-01,\n",
       "            1.6246e-01,  2.7292e-01,  1.3545e-01,  1.8253e-01, -1.4368e-01],\n",
       "          [ 1.3583e-01, -1.9997e-01,  4.0899e-02,  2.4449e-01,  2.3065e-01,\n",
       "            2.6519e-01,  2.9353e-01, -6.0320e-02, -1.3553e-02, -3.1406e-01],\n",
       "          [-1.2928e-01,  7.3206e-03,  1.1126e-01,  1.9350e-01, -3.1322e-01,\n",
       "            8.9916e-02, -1.0030e-01, -1.2519e-02, -2.2629e-01, -1.5398e-01],\n",
       "          [-2.5455e-01,  1.2415e-01,  2.9752e-01,  8.2137e-02,  6.7493e-02,\n",
       "           -2.9322e-01, -2.8226e-01, -2.3237e-01, -2.5609e-01,  2.8801e-01],\n",
       "          [-6.2254e-02,  7.3695e-02, -2.8578e-02, -8.7642e-02, -2.5458e-01,\n",
       "           -1.2303e-01,  2.1368e-01, -2.9483e-01,  5.5304e-02,  4.8675e-02],\n",
       "          [-3.0022e-01, -3.0555e-01,  1.9122e-01,  8.4391e-02,  1.9612e-02,\n",
       "           -1.4698e-01,  3.3975e-02,  1.4176e-01,  3.5252e-02, -2.9374e-01],\n",
       "          [ 2.7638e-01,  1.7209e-01, -1.4526e-01, -2.8829e-01,  6.6389e-02,\n",
       "           -1.9309e-02,  5.8053e-02,  2.0183e-01, -3.8841e-02,  2.8843e-01],\n",
       "          [ 1.6467e-01,  1.6661e-01,  1.5551e-01, -2.4011e-01,  2.8990e-01,\n",
       "            2.9283e-01, -1.0134e-02, -1.1319e-02, -4.4059e-02,  6.6865e-02]],\n",
       "         requires_grad=True)),\n",
       " ('l1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.2425,  0.2314, -0.1572, -0.1009,  0.1799, -0.0433,  0.1876,  0.1123,\n",
       "          -0.1942, -0.1027, -0.2594, -0.0921, -0.2933, -0.0830,  0.1133, -0.2699,\n",
       "          -0.2060,  0.0105,  0.2752,  0.1847, -0.0161, -0.2879, -0.0754, -0.1754,\n",
       "          -0.1759,  0.1248,  0.1418,  0.1774,  0.2613, -0.1779,  0.2886,  0.2846,\n",
       "          -0.1649, -0.2325, -0.0298, -0.1022,  0.1465, -0.2180, -0.2355,  0.2196,\n",
       "           0.2321,  0.0298,  0.1032,  0.1351,  0.1854, -0.1183,  0.1548,  0.1201,\n",
       "          -0.0863,  0.1107], requires_grad=True)),\n",
       " ('l2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0576, -0.0214, -0.1368,  0.0431, -0.1149,  0.0932,  0.0479,  0.0123,\n",
       "            0.0521,  0.0302, -0.0089, -0.1056, -0.1231, -0.0369, -0.0052,  0.0333,\n",
       "            0.0945, -0.1342, -0.0265, -0.0982, -0.1210, -0.0293,  0.0418,  0.1390,\n",
       "            0.1271, -0.0432,  0.1391,  0.0855, -0.0691,  0.1207,  0.1281,  0.1412,\n",
       "            0.0101,  0.0819, -0.1004,  0.1310,  0.0594, -0.1082,  0.0119, -0.0590,\n",
       "           -0.1012, -0.0986,  0.0436,  0.0737,  0.0712,  0.0088, -0.1098, -0.0744,\n",
       "            0.1225, -0.0999]], requires_grad=True)),\n",
       " ('l2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0689], requires_grad=True))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('l1', Linear(in_features=10, out_features=50, bias=True)),\n",
       " ('l2', Linear(in_features=50, out_features=1, bias=True))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('',\n",
       "  Model(\n",
       "    (l1): Linear(in_features=10, out_features=50, bias=True)\n",
       "    (l2): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )),\n",
       " ('l1', Linear(in_features=10, out_features=50, bias=True)),\n",
       " ('l2', Linear(in_features=50, out_features=1, bias=True))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=50, bias=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weight', 'bias']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k[0] for k in list(model.l1.named_parameters())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            self.add_module(f'layer_{i}', layer)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=10, out_features=50, bias=True)\n",
       "  (layer_1): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [nn.Linear(10, 50), nn.Linear(50, 1)]\n",
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=10, out_features=50, bias=True)\n",
       "    (1): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=50, bias=True)\n",
       "  (1): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class optimizer:\n",
    "    def __init__(self, parameters, lr):\n",
    "        self.parameters = list(parameters)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(step):\n",
    "        with torch.no_grad():\n",
    "            for p in self.parameters:\n",
    "                p -= lr * p.grad\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters:\n",
    "            p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ds = Dataset(x_train, y_train)\n",
    "valid_ds = Dataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "assert len(train_ds) == x_train.shape[0]\n",
    "assert len(valid_ds) == x_valid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, ys = train_ds[:5]\n",
    "xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    def __init__(self, ds, bs):\n",
    "        self.ds = ds\n",
    "        self.bs = bs\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs):\n",
    "            yield self.ds[i:i + self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dl = Dataloader(train_ds, 20)\n",
    "valid_dl = Dataloader(valid_ds, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    def __init__(self, ds, bs, shuffle=True):\n",
    "        self.ds = ds\n",
    "        self.bs = bs\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.idxs = torch.randperm(len(\n",
    "            self.ds)) if self.shuffle else torch.arange(len(self.ds))\n",
    "        for i in range(0, len(self.ds), self.bs):\n",
    "            yield self.idxs[i:i + self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([34983, 49936, 33344, 35268, 32597]),\n",
       " tensor([34399, 44867, 36841, 41903, 36888]),\n",
       " tensor([28704, 29728, 10027, 34329, 35618]),\n",
       " tensor([23584,  6719, 33730, 49827, 25957]),\n",
       " tensor([35690, 49254, 31749, 25510, 41645]),\n",
       " tensor([22681, 32009, 39069, 43777,  1270]),\n",
       " tensor([29216, 40426, 31903,  4805, 24899]),\n",
       " tensor([35631, 39481,  7338, 15050, 14597]),\n",
       " tensor([13889,   856, 28100,  2532,  9595]),\n",
       " tensor([ 8392,  2059, 12083, 16855,  2615])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sampler = Sampler(train_ds, 5, shuffle=True)\n",
    "[o for o in train_sampler][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 2, 3, 4]),\n",
       " tensor([5, 6, 7, 8, 9]),\n",
       " tensor([10, 11, 12, 13, 14]),\n",
       " tensor([15, 16, 17, 18, 19]),\n",
       " tensor([20, 21, 22, 23, 24]),\n",
       " tensor([25, 26, 27, 28, 29]),\n",
       " tensor([30, 31, 32, 33, 34]),\n",
       " tensor([35, 36, 37, 38, 39]),\n",
       " tensor([40, 41, 42, 43, 44]),\n",
       " tensor([45, 46, 47, 48, 49])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sampler = Sampler(train_ds, 5, shuffle=False)\n",
    "[o for o in train_sampler][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs, ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    def __init__(self, ds, sampler, bs, collate_fn=collate):\n",
    "        self.ds = ds\n",
    "        self.bs = bs\n",
    "        self.sampler = sampler\n",
    "        self.collate = collate_fn\n",
    "\n",
    "    def __iter__(self):\n",
    "        for s in sampler:\n",
    "            yield self.collate([self.ds[i] for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        # Handle batchnorm / dropout\n",
    "        model.train()\n",
    "#         print(model.training)\n",
    "        for xb,yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "#         print(model.training)\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc = 0., 0.\n",
    "            for xb, yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                tot_loss += loss_func(pred, yb) * len(xb)\n",
    "                tot_acc  += accuracy (pred,yb) * len(xb)\n",
    "        nv = len(valid_ds)\n",
    "        print(epoch, tot_loss / nv, tot_acc / nv)\n",
    "    return tot_loss / nv, tot_acc / nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [nn.Linear(x_train.shape[1], 50), nn.ReLU(), nn.Linear(50, 10)]\n",
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.2036) tensor(0.9387)\n",
      "1 tensor(0.1888) tensor(0.9452)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.1888), tensor(0.9452))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(2, model, F.cross_entropy, opt.SGD(model.parameters(), lr=.5), train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class DataBunch:\n",
    "    def __init__(self, train_dl, valid_dl, c=None):\n",
    "        self.train_dl = train_dl\n",
    "        self.valid_dl = valid_dl\n",
    "        self.c = c\n",
    "    \n",
    "    @property\n",
    "    def train_ds(self):\n",
    "        return self.train_dl.dataset\n",
    "    \n",
    "    @property\n",
    "    def valid_ds(self):\n",
    "        return self.valid_dl.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs * 2, shuffle=False, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64\n",
    "nh = 50\n",
    "c = y_train.max().item() + 1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, valid_ds, bs))\n",
    "assert len(train_ds) == len(data.train_ds)\n",
    "assert len(valid_ds) == len(data.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    def __init__(self, model, opt, loss_func, data):\n",
    "        self.model = model\n",
    "        self.opt = opt\n",
    "        self.loss_func = loss_func\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "layers = [nn.Linear(x_train.shape[1], nh), nn.ReLU(), nn.Linear(50, c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model(layers, lr):\n",
    "    model = nn.Sequential(*layers)\n",
    "    optimizer = opt.SGD(model.parameters(), lr=lr)\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner = Learner(*get_model(layers, lr=.5), \n",
    "                  F.cross_entropy,\n",
    "                  data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fit(epochs, learner):\n",
    "    '''Fit learner.model'''\n",
    "    for epoch in range(epochs):\n",
    "        learner.model.train()\n",
    "        for xb, yb in learner.data.train_dl:\n",
    "            preds = learner.model(xb)\n",
    "            loss = learner.loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            learner.opt.step()\n",
    "            learner.opt.zero_grad()\n",
    "\n",
    "        learner.model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_acc, tot_loss = 0., 0.\n",
    "            for xb, yb in learner.data.valid_dl:\n",
    "                preds = learner.model(xb)\n",
    "                loss = learner.loss_func(preds, yb)\n",
    "                tot_acc += (accuracy(preds, yb) * len(xb))\n",
    "                tot_loss += (loss * len(xb))\n",
    "        n_valid = len(learner.data.valid_ds)\n",
    "        print(\n",
    "            f'Epoch {epoch} : Loss = {tot_loss / n_valid:.2}, Accuracy = {tot_acc / n_valid:.2%}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Loss = 0.16, Accuracy = 95.22%\n",
      "Epoch 1 : Loss = 0.13, Accuracy = 96.43%\n",
      "Epoch 2 : Loss = 0.19, Accuracy = 93.73%\n",
      "Epoch 3 : Loss = 0.11, Accuracy = 96.61%\n"
     ]
    }
   ],
   "source": [
    "fit(4, learner)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
